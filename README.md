# Projeto Hydra: Pipeline de Dados H√≠brido com Azure e Databricks

![Status: Conclu√≠do](https://img.shields.io/badge/status-conclu√≠do-brightgreen)
![Tecnologia](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoftazure&logoColor=white)
![Framework](https://img.shields.io/badge/Databricks-E25A1C?style=for-the-badge&logo=databricks&logoColor=white)
![Linguagem](https://img.shields.io/badge/PySpark-F88B01?style=for-the-badge&logo=apache-spark&logoColor=white)

***

## üéØ Vis√£o Geral do Projeto
Este projeto implementa um pipeline de dados de ponta-a-ponta na nuvem **Azure**, com foco em processamento **h√≠brido (streaming e batch)**. O objetivo foi aplicar as melhores pr√°ticas de engenharia de dados utilizando uma stack moderna, com **Azure Databricks** para processamento com **PySpark**, **Delta Lake** como camada de armazenamento Lakehouse, e **Azure Functions** para ingest√£o serverless.

Este reposit√≥rio serve como um portf√≥lio pr√°tico, demonstrando compet√™ncias em **arquitetura de dados**, processamento distribu√≠do, qualidade de dados e **pr√°ticas de DevOps** para automa√ß√£o e orquestra√ß√£o de pipelines.

***

## üõ†Ô∏è Ferramentas e Tecnologias
| Ferramenta | Prop√≥sito |
| :--- | :--- |
| **Azure Functions** | **Ingest√£o Serverless:** Executa um produtor de eventos agendado para simular um fluxo cont√≠nuo de dados. |
| **Azure Event Hubs** | **Buffer de Streaming:** Servi√ßo de mensageria que recebe o fluxo de dados e o disponibiliza para consumo. |
| **Azure Data Lake Gen2**| **Data Lakehouse:** Camada de armazenamento para as tabelas Delta nas camadas `raw`, `core` e `analytics`. |
| **Azure Databricks** | **Plataforma Unificada:** Ambiente para desenvolvimento, execu√ß√£o e orquestra√ß√£o de todo o pipeline com PySpark. |
| **Delta Lake** | **Camada de Armazenamento:** Formato de tabela que garante transa√ß√µes ACID, confiabilidade e performance ao Data Lake. |
| **PySpark** | **Processamento:** Utilizado para todas as transforma√ß√µes, incluindo **Streaming Estruturado** e l√≥gicas avan√ßadas com **Window Functions**. |
| **PyDeequ** | **Qualidade de Dados:** Framework para definir e executar testes de qualidade de dados de forma declarativa sobre os DataFrames. |
| **Databricks Jobs & Bundles**| **Orquestra√ß√£o & DevOps:** Automa√ß√£o do pipeline (DAG) e defini√ß√£o da infraestrutura do Job como c√≥digo (`databricks.yml`). |
| **Git & GitHub** | **Versionamento:** Sistema para versionamento de todo o c√≥digo do projeto, incluindo notebooks e defini√ß√µes de job. |

***

## üèóÔ∏è Arquitetura da Solu√ß√£o
A solu√ß√£o utiliza uma arquitetura h√≠brida, onde um caminho batch enriquece os dados que s√£o processados em tempo real pelo caminho de streaming. A orquestra√ß√£o √© gerenciada pelo Databricks Jobs, seguindo a arquitetura **Medallion**.

```mermaid
graph TD
    subgraph Azure Cloud
        direction LR
        subgraph Ingest√£o Serverless
            A[Azure Function] -- Gera lote de transa√ß√µes a cada 5 min --> B[Azure Event Hubs];
        end
        
        subgraph Databricks [Plataforma de Dados]
            direction TB
            
            subgraph Pipeline de Ingest√£o [Streaming]
                B -- L√™ Stream --> C{Notebook 01: Ingestion};
            end

            subgraph Pipeline de Alertas [Streaming]
                F[Core Layer: Perfis] -- Join Est√°tico --> G{Notebook 02: Real-Time Alerts};
            end

            subgraph Pipeline de Perfis [Batch - Job Di√°rio]
                 E -- L√™ Batch --> D{Notebook 03: Profiling};
            end
            
            subgraph Pipeline de Qualidade [Batch]
                H[Analytics Layer: Alertas] -- L√™ Batch --> I{Notebook 04: Quality Checks};
            end

            C -- Salva Stream --> E[Raw Layer: Transa√ß√µes];
            D -- MERGE --> F;
            E -- L√™ Stream --> G;
            G -- Salva Stream --> H;
        end
    end

    style A fill:#722bd1,stroke:#333,stroke-width:2px,color:#fff
    style B fill:#0078D4,stroke:#333,stroke-width:2px,color:#fff
    style E fill:#add8e6,stroke:#333,stroke-width:2px,color:#000
    style F fill:#ff7f50,stroke:#333,stroke-width:2px,color:#000
    style H fill:#3cb371,stroke:#333,stroke-width:2px,color:#000
```
* **Raw (Bronze):** Um pipeline de streaming (`01_ingestion`) consome os dados do Event Hubs e os salva em formato Delta, criando uma c√≥pia fiel da origem.
* **Core (Silver):** Um pipeline batch (`03_profiling`) roda diariamente, lendo os dados da camada `raw` para calcular e atualizar os perfis de comportamento de cada usu√°rio, salvando-os na camada `core`.
* **Analytics (Gold):** Um segundo pipeline de streaming (`02_alerts`) l√™ as novas transa√ß√µes da camada `raw`, as enriquece em tempo real com os perfis da camada `core` (**stream-table join**) e salva os resultados na camada `analytics`.

***

## ‚ú® Destaques de Engenharia com PySpark

* **Engenharia de Features com Window Functions:** Para enriquecer os perfis de usu√°rio, foi utilizada uma **Window Function** (`lag`) no PySpark para calcular o tempo decorrido entre as transa√ß√µes de um mesmo usu√°rio. Essa m√©trica (`avg_time_between_tx_sec`) demonstra a aplica√ß√£o de t√©cnicas avan√ßadas de transforma√ß√£o para criar features anal√≠ticas complexas.
* **Processamento de Streaming com Joins:** A l√≥gica de enriquecimento em tempo real foi implementada atrav√©s de um **join de stream-tabela**, uma t√©cnica do Streaming Estruturado que cruza um fluxo de dados cont√≠nuo com uma tabela de dados est√°tica (os perfis de usu√°rio) para adicionar contexto a cada evento.

***

## ‚úÖ DevOps e Qualidade de Dados

* **Qualidade de Dados com PyDeequ:** A confiabilidade do pipeline foi garantida com a biblioteca **PyDeequ**. Foi implementado um conjunto de testes declarativos que rodam como a etapa final do Job, validando a integridade dos dados na camada `core` (unicidade, valores n√£o-negativos, etc.).
* **Orquestra√ß√£o como C√≥digo (Jobs as Code):** Todo o pipeline, incluindo a sequ√™ncia de tarefas **(DAG)**, a configura√ß√£o dos clusters e o agendamento, √© definido como c√≥digo em um arquivo **`databricks.yml`**. Esta abordagem de **Jobs as Code** com Databricks Asset Bundles permite que a orquestra√ß√£o seja versionada no Git e implantada de forma automatizada com a **Databricks CLI**, garantindo consist√™ncia e reprodutibilidade.
* **Seguran√ßa e Governan√ßa:** A comunica√ß√£o entre Databricks e Data Lake √© autenticada via **Microsoft Entra ID (Service Principal)**, seguindo o **Princ√≠pio do Menor Privil√©gio** com pap√©is RBAC espec√≠ficos. Segredos s√£o gerenciados de forma segura no **Azure Key Vault**.

***

## üöÄ Pr√≥ximos Passos
* **CI/CD com GitHub Actions:** Implementar um workflow no GitHub Actions que, a cada `push` na branch `main`, automaticamente executa o `databricks bundle deploy` para atualizar o Job em produ√ß√£o.
* **Monitoramento:** Configurar alertas no Azure Monitor para notificar sobre falhas no Job ou na Azure Function.
* **Infraestrutura como C√≥digo (IaC):** Utilizar Terraform ou Bicep para provisionar toda a infraestrutura do Azure (Data Lake, Event Hubs, etc.) de forma automatizada.
